{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "udacity_capstone.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WtesfTyQBU3",
        "colab_type": "text"
      },
      "source": [
        "# Download the kaggle data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qGzsdQK16Z",
        "colab_type": "code",
        "outputId": "85234627-62f7-4f99-e834-4b7d7b280ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c humpback-whale-identification\n",
        "!rm -rf input\n",
        "!mkdir -p input\n",
        "!unzip -q train.zip -d input/train\n",
        "#!ls input/train"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpFPr0BgRgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5c15a4e-0058-44d2-d9cb-918818d2678f"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mplimg\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF8I-wjLONtZ",
        "colab_type": "text"
      },
      "source": [
        "# Explore the training data.\n",
        "Let us explore the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6_zz3XOaSY",
        "colab_type": "code",
        "outputId": "31682579-11c7-48b7-9dbc-7e2b4b6a4021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000e88ab.jpg</td>\n",
              "      <td>w_f48451c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0001f9222.jpg</td>\n",
              "      <td>w_c3d896a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00029d126.jpg</td>\n",
              "      <td>w_20df2c5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00050a15a.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0005c1ef8.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image         Id\n",
              "0  0000e88ab.jpg  w_f48451c\n",
              "1  0001f9222.jpg  w_c3d896a\n",
              "2  00029d126.jpg  w_20df2c5\n",
              "3  00050a15a.jpg  new_whale\n",
              "4  0005c1ef8.jpg  new_whale"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB4uvGkIQsCA",
        "colab_type": "code",
        "outputId": "3f20db86-6bb3-4156-a68f-10959eada380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_df.Id.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "new_whale    9664\n",
              "w_23a388d      73\n",
              "w_9b5109b      65\n",
              "w_9c506f6      62\n",
              "w_0369a5c      61\n",
              "w_700ebb4      57\n",
              "w_3de579a      54\n",
              "w_564a34b      51\n",
              "w_fd3e556      50\n",
              "w_88e4537      49\n",
              "w_2b069ba      48\n",
              "w_d405854      47\n",
              "w_789c969      45\n",
              "w_f0fe284      45\n",
              "w_343f088      40\n",
              "w_778e474      40\n",
              "w_5e8e218      40\n",
              "w_60ce6fc      37\n",
              "w_a9304b9      37\n",
              "w_5a2634c      37\n",
              "w_6822dbc      36\n",
              "w_af367c3      35\n",
              "w_1ca9ab1      34\n",
              "w_f765256      34\n",
              "w_17b0d3a      33\n",
              "w_d72771c      32\n",
              "w_8c25681      31\n",
              "w_08630fd      31\n",
              "w_6cda039      31\n",
              "w_04003e9      30\n",
              "             ... \n",
              "w_90df70c       1\n",
              "w_ba668da       1\n",
              "w_2e1416e       1\n",
              "w_1e81b43       1\n",
              "w_702b2c4       1\n",
              "w_74192ac       1\n",
              "w_1ee38d5       1\n",
              "w_34941d8       1\n",
              "w_56e52fb       1\n",
              "w_2b1b04e       1\n",
              "w_e759cd6       1\n",
              "w_f0ba4a2       1\n",
              "w_d4fc12d       1\n",
              "w_2ae40f9       1\n",
              "w_bc9188e       1\n",
              "w_f347577       1\n",
              "w_97074d8       1\n",
              "w_408f9ea       1\n",
              "w_b51e6f6       1\n",
              "w_46a38a6       1\n",
              "w_3c58b68       1\n",
              "w_01ed442       1\n",
              "w_7d9d014       1\n",
              "w_ae70500       1\n",
              "w_8261f4d       1\n",
              "w_d1836e5       1\n",
              "w_b1c5c0b       1\n",
              "w_0fb38fe       1\n",
              "w_6f927a1       1\n",
              "w_eae7e41       1\n",
              "Name: Id, Length: 5005, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3bAW_bFTBax",
        "colab_type": "code",
        "outputId": "af36b5f7-ee45-435f-f630-1f2b85e4a0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Number of rows in train.csv', len(train_df))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in train.csv 25361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7vOENFsOhBP",
        "colab_type": "text"
      },
      "source": [
        "# Identify the data points\n",
        "\n",
        "## train.csv\n",
        "There are 25361 rows in train.csv.  Which corresponds to the image entries in train.zip\n",
        "We can see that the train.csv file has two data fields.  \n",
        "* Image : The whale image file name\n",
        "* Id is the whale Id.\n",
        "Each whale is assigned a unique Id.  The unidentified whale's are assigned an Id new_whale.  \n",
        "\n",
        "\n",
        "## train.zip\n",
        "There are 25361 image files in train.zip file.  It has been extracted to input/train folder.  The filename corresponds to the Image column in train.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJZxvxFdnAQ",
        "colab_type": "text"
      },
      "source": [
        "# Split the data into training, validation & test datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEfUZG3ddmXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode labels to integers using sklearning.preprocessing.LabelEncoder\n",
        "# Convert the integer encoded array to \n",
        "le = LabelEncoder()\n",
        "def transform_category(y):\n",
        "  le.fit(y)\n",
        "  y_transform = le.fit_transform(y)\n",
        "  y_transform = np_utils.to_categorical(y_transform, num_classes=len(le.classes_))\n",
        "  return y_transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P63g4o2eCsV",
        "colab_type": "code",
        "outputId": "391f34f7-c1a2-4499-bf72-5bd24b221882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "labels = train_df.Id\n",
        "y_transform = transform_category(labels)\n",
        "\n",
        "print(y_transform,len(y_transform))\n",
        "\n",
        "X_train, X_tmp, Y_train, Y_tmp = train_test_split(train_df, y_transform, test_size=0.2, random_state=5)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test   = train_test_split(X_tmp, Y_tmp, test_size=0.5, random_state=5)\n",
        "\n",
        "print('Training, Validation & testing data size', len(X_train),len(X_val), len(X_test))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 25361\n",
            "Training, Validation & testing data size 20288 2536 2537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNl8gYrcbtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "2aa10bb7-9f1d-4d58-b758-60dfe9f5989c"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (100, 100, 3)))\n",
        "\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
        "model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation=\"relu\", name='rl'))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(5005, activation='softmax', name='sm'))\n",
        "\n",
        "print(model.output_shape)\n",
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 03:16:40.223158 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 03:16:40.243598 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 03:16:40.257653 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 03:16:40.289767 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0718 03:16:40.290764 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0718 03:16:42.056600 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0718 03:16:42.133335 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0718 03:16:42.152755 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0718 03:16:42.179415 140048880281472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0718 03:16:42.180289 140048880281472 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(None, 5005)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv0 (Conv2D)               (None, 94, 94, 32)        4736      \n",
            "_________________________________________________________________\n",
            "bn0 (BatchNormalization)     (None, 94, 94, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 94, 94, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pool (MaxPooling2D)      (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 45, 45, 64)        0         \n",
            "_________________________________________________________________\n",
            "avg_pool (AveragePooling2D)  (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "rl (Dense)                   (None, 500)               7200500   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "sm (Dense)                   (None, 5005)              2507505   \n",
            "=================================================================\n",
            "Total params: 9,731,365\n",
            "Trainable params: 9,731,301\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLevu9HUjD-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_images(data):\n",
        "    \n",
        "    print(\"Preparing images\")\n",
        "    \n",
        "    images = np.zeros((len(data), 100, 100, 3))\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    for fig in data.Image:\n",
        "        #load images into images of size 100x100x3\n",
        "        img = image.load_img(\"input/train/\"+fig, target_size=(100, 100, 3))\n",
        "        x = image.img_to_array(img)\n",
        "        x = preprocess_input(x)\n",
        "        images[count] = x\n",
        "        if (count%500 == 0):\n",
        "            print(\"Processing image: \", count+1, \", \", fig)\n",
        "        count += 1\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    print(\"Finished!\")\n",
        "            \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bHgwkdQqMNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "30874a54-89e6-4778-da25-1b920827f09c"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 03:16:42.237782 140048880281472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czcKfy5IjWqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ee5072d-61ba-4297-cb26-53df3dfb1d0f"
      },
      "source": [
        "x_train_images = prepare_images(X_train)\n",
        "x_train_images /= 255\n",
        "\n",
        "print(\"Shape X-train: \", x_train_images.shape)\n",
        "\n",
        "x_val_images = prepare_images(X_val)\n",
        "x_val_images /= 255\n",
        "\n",
        "print(\"Shape X-val: \", x_val_images.shape)\n",
        "\n",
        "x_test_images = prepare_images(X_test)\n",
        "x_test_images /= 255\n",
        "\n",
        "print(\"Shape X-test: \", x_test_images.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing images\n",
            "Processing image:  1 ,  5e2572252.jpg\n",
            "Processing image:  501 ,  b728ef1e9.jpg\n",
            "Processing image:  1001 ,  942ab5de3.jpg\n",
            "Processing image:  1501 ,  dd4cfa29f.jpg\n",
            "Processing image:  2001 ,  614f10ee7.jpg\n",
            "Processing image:  2501 ,  db9667359.jpg\n",
            "Processing image:  3001 ,  86c9aa515.jpg\n",
            "Processing image:  3501 ,  7f3aafbd2.jpg\n",
            "Processing image:  4001 ,  6f0c3deb4.jpg\n",
            "Processing image:  4501 ,  444b09aca.jpg\n",
            "Processing image:  5001 ,  f532c9318.jpg\n",
            "Processing image:  5501 ,  f2d3d0d0f.jpg\n",
            "Processing image:  6001 ,  6ca37fe7c.jpg\n",
            "Processing image:  6501 ,  3394e12db.jpg\n",
            "Processing image:  7001 ,  feddb3aa9.jpg\n",
            "Processing image:  7501 ,  3a8173905.jpg\n",
            "Processing image:  8001 ,  16ddf58df.jpg\n",
            "Processing image:  8501 ,  64b519010.jpg\n",
            "Processing image:  9001 ,  c2a02f80e.jpg\n",
            "Processing image:  9501 ,  770cb755e.jpg\n",
            "Processing image:  10001 ,  803515118.jpg\n",
            "Processing image:  10501 ,  5e8632b10.jpg\n",
            "Processing image:  11001 ,  5f37d323c.jpg\n",
            "Processing image:  11501 ,  204823b38.jpg\n",
            "Processing image:  12001 ,  27fdfe88c.jpg\n",
            "Processing image:  12501 ,  2272e1d48.jpg\n",
            "Processing image:  13001 ,  a7505ae38.jpg\n",
            "Processing image:  13501 ,  6faef4f7b.jpg\n",
            "Processing image:  14001 ,  788a2531c.jpg\n",
            "Processing image:  14501 ,  4e8713f2d.jpg\n",
            "Processing image:  15001 ,  a61a7cbf1.jpg\n",
            "Processing image:  15501 ,  f0109bc35.jpg\n",
            "Processing image:  16001 ,  f842d2d41.jpg\n",
            "Processing image:  16501 ,  1973d2873.jpg\n",
            "Processing image:  17001 ,  38b192e64.jpg\n",
            "Processing image:  17501 ,  b69a3106c.jpg\n",
            "Processing image:  18001 ,  898201c7f.jpg\n",
            "Processing image:  18501 ,  065fbc00f.jpg\n",
            "Processing image:  19001 ,  f5cfbf2df.jpg\n",
            "Processing image:  19501 ,  adaa80347.jpg\n",
            "Processing image:  20001 ,  a3785aebd.jpg\n",
            "Finished!\n",
            "Shape X-train:  (20288, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  f6992fe3c.jpg\n",
            "Processing image:  501 ,  3c9ccb9b5.jpg\n",
            "Processing image:  1001 ,  62a96dde1.jpg\n",
            "Processing image:  1501 ,  f7a34b30e.jpg\n",
            "Processing image:  2001 ,  03e3599f3.jpg\n",
            "Processing image:  2501 ,  b9c0dba6f.jpg\n",
            "Finished!\n",
            "Shape X-val:  (2536, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  448ae30f9.jpg\n",
            "Processing image:  501 ,  88766032d.jpg\n",
            "Processing image:  1001 ,  d5258d97c.jpg\n",
            "Processing image:  1501 ,  2e0f1128d.jpg\n",
            "Processing image:  2001 ,  4f72b1b40.jpg\n",
            "Processing image:  2501 ,  60bee807a.jpg\n",
            "Finished!\n",
            "Shape X-test:  (2537, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HNzk69iDTmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_per_image(label, predictions):\n",
        "    \"\"\"Computes the precision score of one image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    label : string\n",
        "            The true label of the image\n",
        "    predictions : list\n",
        "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"    \n",
        "    try:\n",
        "        return 1 / (predictions[:5].index(label) + 1)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def map_per_set(labels, predictions):\n",
        "    \"\"\"Computes the average over multiple images.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    labels : list\n",
        "             A list of the true labels. (Only one true label per images allowed!)\n",
        "    predictions : list of list\n",
        "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"\n",
        "    return np.mean([map_per_image(l, p) for l,p in zip(labels, predictions)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1RdJJQdkn0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c48d970d-3a01-4ab5-d884-4e5296529ab2"
      },
      "source": [
        "import gc\n",
        "history = model.fit(x_train_images, Y_train, epochs=100, batch_size=100, verbose=1,\n",
        "                   validation_data=(x_val_images,Y_val))\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 03:20:48.420294 140048880281472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20288 samples, validate on 2536 samples\n",
            "Epoch 1/100\n",
            "20288/20288 [==============================] - 18s 908us/step - loss: 6.1984 - acc: 0.3798 - val_loss: 6.8944 - val_acc: 0.3825\n",
            "Epoch 2/100\n",
            "20288/20288 [==============================] - 13s 646us/step - loss: 5.9181 - acc: 0.3815 - val_loss: 5.9683 - val_acc: 0.3825\n",
            "Epoch 3/100\n",
            "20288/20288 [==============================] - 13s 646us/step - loss: 5.7978 - acc: 0.3815 - val_loss: 5.7611 - val_acc: 0.3825\n",
            "Epoch 4/100\n",
            "20288/20288 [==============================] - 13s 643us/step - loss: 5.7167 - acc: 0.3815 - val_loss: 5.7281 - val_acc: 0.3825\n",
            "Epoch 5/100\n",
            "20288/20288 [==============================] - 13s 637us/step - loss: 5.6655 - acc: 0.3815 - val_loss: 5.7618 - val_acc: 0.3825\n",
            "Epoch 6/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 5.6244 - acc: 0.3815 - val_loss: 5.7577 - val_acc: 0.3825\n",
            "Epoch 7/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 5.5912 - acc: 0.3815 - val_loss: 5.8071 - val_acc: 0.3825\n",
            "Epoch 8/100\n",
            "20288/20288 [==============================] - 13s 637us/step - loss: 5.5348 - acc: 0.3815 - val_loss: 5.7935 - val_acc: 0.3825\n",
            "Epoch 9/100\n",
            "20288/20288 [==============================] - 13s 644us/step - loss: 5.4763 - acc: 0.3815 - val_loss: 5.8204 - val_acc: 0.3825\n",
            "Epoch 10/100\n",
            "20288/20288 [==============================] - 13s 645us/step - loss: 5.4213 - acc: 0.3815 - val_loss: 5.8333 - val_acc: 0.3825\n",
            "Epoch 11/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 5.3382 - acc: 0.3815 - val_loss: 5.8493 - val_acc: 0.3825\n",
            "Epoch 12/100\n",
            "20288/20288 [==============================] - 13s 640us/step - loss: 5.2736 - acc: 0.3815 - val_loss: 5.9303 - val_acc: 0.3825\n",
            "Epoch 13/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 5.1775 - acc: 0.3815 - val_loss: 5.8944 - val_acc: 0.3825\n",
            "Epoch 14/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 5.0675 - acc: 0.3815 - val_loss: 5.9673 - val_acc: 0.3825\n",
            "Epoch 15/100\n",
            "20288/20288 [==============================] - 13s 636us/step - loss: 4.9583 - acc: 0.3815 - val_loss: 5.9749 - val_acc: 0.3825\n",
            "Epoch 16/100\n",
            "20288/20288 [==============================] - 13s 636us/step - loss: 4.8424 - acc: 0.3815 - val_loss: 5.9809 - val_acc: 0.3825\n",
            "Epoch 17/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 4.6896 - acc: 0.3816 - val_loss: 6.1517 - val_acc: 0.3825\n",
            "Epoch 18/100\n",
            "20288/20288 [==============================] - 13s 640us/step - loss: 4.5335 - acc: 0.3821 - val_loss: 6.1308 - val_acc: 0.3825\n",
            "Epoch 19/100\n",
            "20288/20288 [==============================] - 13s 644us/step - loss: 4.3330 - acc: 0.3838 - val_loss: 6.2273 - val_acc: 0.3825\n",
            "Epoch 20/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 4.1141 - acc: 0.3879 - val_loss: 6.2843 - val_acc: 0.3825\n",
            "Epoch 21/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 3.8723 - acc: 0.3950 - val_loss: 6.3721 - val_acc: 0.3829\n",
            "Epoch 22/100\n",
            "20288/20288 [==============================] - 13s 642us/step - loss: 3.6275 - acc: 0.4058 - val_loss: 6.4769 - val_acc: 0.3829\n",
            "Epoch 23/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 3.4018 - acc: 0.4193 - val_loss: 6.4628 - val_acc: 0.3825\n",
            "Epoch 24/100\n",
            "20288/20288 [==============================] - 13s 637us/step - loss: 3.1412 - acc: 0.4403 - val_loss: 6.7224 - val_acc: 0.3833\n",
            "Epoch 25/100\n",
            "20288/20288 [==============================] - 13s 636us/step - loss: 2.8822 - acc: 0.4640 - val_loss: 6.7481 - val_acc: 0.3829\n",
            "Epoch 26/100\n",
            "20288/20288 [==============================] - 13s 638us/step - loss: 2.6726 - acc: 0.4881 - val_loss: 6.9318 - val_acc: 0.3833\n",
            "Epoch 27/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 2.4749 - acc: 0.5050 - val_loss: 7.2237 - val_acc: 0.3825\n",
            "Epoch 28/100\n",
            "20288/20288 [==============================] - 13s 640us/step - loss: 2.2895 - acc: 0.5313 - val_loss: 7.2265 - val_acc: 0.3829\n",
            "Epoch 29/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 2.1109 - acc: 0.5518 - val_loss: 7.2187 - val_acc: 0.3833\n",
            "Epoch 30/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 1.9621 - acc: 0.5726 - val_loss: 7.4073 - val_acc: 0.3845\n",
            "Epoch 31/100\n",
            "20288/20288 [==============================] - 13s 638us/step - loss: 1.8036 - acc: 0.6028 - val_loss: 7.5123 - val_acc: 0.3841\n",
            "Epoch 32/100\n",
            "20288/20288 [==============================] - 13s 639us/step - loss: 1.6668 - acc: 0.6225 - val_loss: 7.6914 - val_acc: 0.3841\n",
            "Epoch 33/100\n",
            "20288/20288 [==============================] - 13s 644us/step - loss: 1.5787 - acc: 0.6388 - val_loss: 7.6667 - val_acc: 0.3841\n",
            "Epoch 34/100\n",
            "20288/20288 [==============================] - 13s 641us/step - loss: 1.4946 - acc: 0.6530 - val_loss: 7.7936 - val_acc: 0.3837\n",
            "Epoch 35/100\n",
            "20288/20288 [==============================] - 13s 638us/step - loss: 1.3833 - acc: 0.6751 - val_loss: 8.0073 - val_acc: 0.3845\n",
            "Epoch 36/100\n",
            "13800/20288 [===================>..........] - ETA: 3s - loss: 1.2870 - acc: 0.6959"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvw1d3YmeYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x_test_images, verbose=1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_RTx0Sfs37Gk",
        "colab": {}
      },
      "source": [
        "predictions=[]\n",
        "for i, p in enumerate(pred):\n",
        "  predictions.append(le.inverse_transform(p.argsort()[-5:][::-1]).tolist())\n",
        "print(map_per_set(X_test.Id, predictions ))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}