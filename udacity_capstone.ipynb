{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "udacity_capstone.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WtesfTyQBU3",
        "colab_type": "text"
      },
      "source": [
        "# Download the kaggle data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qGzsdQK16Z",
        "colab_type": "code",
        "outputId": "ee49cdb4-1687-4408-895d-9eb9957695f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c humpback-whale-identification\n",
        "!rm -rf input\n",
        "!mkdir -p input\n",
        "!unzip -q train.zip -d input/train\n",
        "#!ls input/train\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/498k [00:00<?, ?B/s]\n",
            "100% 498k/498k [00:00<00:00, 33.8MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/594k [00:00<?, ?B/s]\n",
            "100% 594k/594k [00:00<00:00, 81.0MB/s]\n",
            "Downloading test.zip to /content\n",
            "100% 1.35G/1.35G [00:16<00:00, 104MB/s] \n",
            "100% 1.35G/1.35G [00:16<00:00, 86.7MB/s]\n",
            "Downloading train.zip to /content\n",
            "100% 4.15G/4.16G [00:50<00:00, 31.4MB/s]\n",
            "100% 4.16G/4.16G [00:50<00:00, 89.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpFPr0BgRgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "337cb64d-7ba5-449f-ef85-502dc267a650"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mplimg\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF8I-wjLONtZ",
        "colab_type": "text"
      },
      "source": [
        "# Explore the training data.\n",
        "Let us explore the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6_zz3XOaSY",
        "colab_type": "code",
        "outputId": "4cebcc5b-24ad-4ea7-c8e7-7797d74f5fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000e88ab.jpg</td>\n",
              "      <td>w_f48451c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0001f9222.jpg</td>\n",
              "      <td>w_c3d896a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00029d126.jpg</td>\n",
              "      <td>w_20df2c5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00050a15a.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0005c1ef8.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image         Id\n",
              "0  0000e88ab.jpg  w_f48451c\n",
              "1  0001f9222.jpg  w_c3d896a\n",
              "2  00029d126.jpg  w_20df2c5\n",
              "3  00050a15a.jpg  new_whale\n",
              "4  0005c1ef8.jpg  new_whale"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3bAW_bFTBax",
        "colab_type": "code",
        "outputId": "158b15f9-ed77-4200-c46d-c9c00e95b06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Number of rows in train.csv', len(train_df))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in train.csv 25361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7vOENFsOhBP",
        "colab_type": "text"
      },
      "source": [
        "# Identify the data points\n",
        "\n",
        "## train.csv\n",
        "There are 25361 rows in train.csv.  Which corresponds to the image entries in train.zip\n",
        "We can see that the train.csv file has two data fields.  \n",
        "* Image : The whale image file name\n",
        "* Id is the whale Id.\n",
        "Each whale is assigned a unique Id.  The unidentified whale's are assigned an Id new_whale.  \n",
        "\n",
        "\n",
        "## train.zip\n",
        "There are 25361 image files in train.zip file.  It has been extracted to input/train folder.  The filename corresponds to the Image column in train.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJZxvxFdnAQ",
        "colab_type": "text"
      },
      "source": [
        "# Split the data into training, validation & test datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P63g4o2eCsV",
        "colab_type": "code",
        "outputId": "e729349d-385f-4f88-b941-42423e5c7162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "labels = train_df.Id\n",
        "# Encode labels to integers using sklearning.preprocessing.LabelEncoder\n",
        "# Convert the integer encoded array to category\n",
        "le = LabelEncoder()\n",
        "le.fit(labels)\n",
        "y_transform = np_utils.to_categorical(le.transform(labels), num_classes=len(le.classes_))\n",
        "\n",
        "X_train, X_tmp, Y_train, Y_tmp = train_test_split(train_df, y_transform, test_size=0.2, random_state=5)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test   = train_test_split(X_tmp, Y_tmp, test_size=0.5, random_state=5)\n",
        "\n",
        "print('Training, Validation & testing data size', len(X_train),len(X_val), len(X_test))\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training, Validation & testing data size 20288 2536 2537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra5YW9NSxmyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_images(data):\n",
        "    print(\"Preparing images\")\n",
        "    images = np.zeros((len(data), 100, 100, 3))\n",
        "    count = 0\n",
        "    \n",
        "    for fig in data.Image:\n",
        "        #load images into images of size 100x100x3\n",
        "        img = image.load_img(\"input/train/\"+fig, target_size=(100, 100, 3))\n",
        "        x = image.img_to_array(img)\n",
        "        x = preprocess_input(x)\n",
        "        images[count] = x\n",
        "        if (count%500 == 0):\n",
        "            print(\"Processing image: \", count+1, \", \", fig)\n",
        "        count += 1\n",
        "    count = 0\n",
        "    print(\"Finished!\")      \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bqz3rNkvKvf",
        "colab_type": "text"
      },
      "source": [
        "# Create a CNN to create a base line model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNl8gYrcbtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "3f9322e7-403e-4bf2-9be0-4fa3329ef254"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 7, padding = 'same', activation = 'relu', \n",
        "          input_shape = (100, 100, 3))) #RGB image\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 7,  padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 7, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5005, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 07:50:58.943377 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 07:50:58.972382 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 07:50:58.979330 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 07:50:59.004353 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0718 07:50:59.055230 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0718 07:50:59.065801 139980295018368 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 16)      2368      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 33, 33, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 33, 33, 32)        25120     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        100416    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               32500     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5005)              2507505   \n",
            "=================================================================\n",
            "Total params: 2,667,909\n",
            "Trainable params: 2,667,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bHgwkdQqMNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0a98c1fe-b2a7-4a66-ad70-dadd221d8068"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 07:50:59.107206 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 07:50:59.133605 139980295018368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czcKfy5IjWqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4946185-8216-4d68-f21b-f218c87d0b35"
      },
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "x_train_images = prepare_images(X_train)\n",
        "x_train_images /= 255\n",
        "\n",
        "print(\"Shape X-train: \", x_train_images.shape)\n",
        "\n",
        "x_val_images = prepare_images(X_val)\n",
        "x_val_images /= 255\n",
        "\n",
        "print(\"Shape X-val: \", x_val_images.shape)\n",
        "\n",
        "x_test_images = prepare_images(X_test)\n",
        "x_test_images /= 255\n",
        "\n",
        "print(\"Shape X-test: \", x_test_images.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing images\n",
            "Processing image:  1 ,  5e2572252.jpg\n",
            "Processing image:  501 ,  b728ef1e9.jpg\n",
            "Processing image:  1001 ,  942ab5de3.jpg\n",
            "Processing image:  1501 ,  dd4cfa29f.jpg\n",
            "Processing image:  2001 ,  614f10ee7.jpg\n",
            "Processing image:  2501 ,  db9667359.jpg\n",
            "Processing image:  3001 ,  86c9aa515.jpg\n",
            "Processing image:  3501 ,  7f3aafbd2.jpg\n",
            "Processing image:  4001 ,  6f0c3deb4.jpg\n",
            "Processing image:  4501 ,  444b09aca.jpg\n",
            "Processing image:  5001 ,  f532c9318.jpg\n",
            "Processing image:  5501 ,  f2d3d0d0f.jpg\n",
            "Processing image:  6001 ,  6ca37fe7c.jpg\n",
            "Processing image:  6501 ,  3394e12db.jpg\n",
            "Processing image:  7001 ,  feddb3aa9.jpg\n",
            "Processing image:  7501 ,  3a8173905.jpg\n",
            "Processing image:  8001 ,  16ddf58df.jpg\n",
            "Processing image:  8501 ,  64b519010.jpg\n",
            "Processing image:  9001 ,  c2a02f80e.jpg\n",
            "Processing image:  9501 ,  770cb755e.jpg\n",
            "Processing image:  10001 ,  803515118.jpg\n",
            "Processing image:  10501 ,  5e8632b10.jpg\n",
            "Processing image:  11001 ,  5f37d323c.jpg\n",
            "Processing image:  11501 ,  204823b38.jpg\n",
            "Processing image:  12001 ,  27fdfe88c.jpg\n",
            "Processing image:  12501 ,  2272e1d48.jpg\n",
            "Processing image:  13001 ,  a7505ae38.jpg\n",
            "Processing image:  13501 ,  6faef4f7b.jpg\n",
            "Processing image:  14001 ,  788a2531c.jpg\n",
            "Processing image:  14501 ,  4e8713f2d.jpg\n",
            "Processing image:  15001 ,  a61a7cbf1.jpg\n",
            "Processing image:  15501 ,  f0109bc35.jpg\n",
            "Processing image:  16001 ,  f842d2d41.jpg\n",
            "Processing image:  16501 ,  1973d2873.jpg\n",
            "Processing image:  17001 ,  38b192e64.jpg\n",
            "Processing image:  17501 ,  b69a3106c.jpg\n",
            "Processing image:  18001 ,  898201c7f.jpg\n",
            "Processing image:  18501 ,  065fbc00f.jpg\n",
            "Processing image:  19001 ,  f5cfbf2df.jpg\n",
            "Processing image:  19501 ,  adaa80347.jpg\n",
            "Processing image:  20001 ,  a3785aebd.jpg\n",
            "Finished!\n",
            "Shape X-train:  (20288, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  f6992fe3c.jpg\n",
            "Processing image:  501 ,  3c9ccb9b5.jpg\n",
            "Processing image:  1001 ,  62a96dde1.jpg\n",
            "Processing image:  1501 ,  f7a34b30e.jpg\n",
            "Processing image:  2001 ,  03e3599f3.jpg\n",
            "Processing image:  2501 ,  b9c0dba6f.jpg\n",
            "Finished!\n",
            "Shape X-val:  (2536, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  448ae30f9.jpg\n",
            "Processing image:  501 ,  88766032d.jpg\n",
            "Processing image:  1001 ,  d5258d97c.jpg\n",
            "Processing image:  1501 ,  2e0f1128d.jpg\n",
            "Processing image:  2001 ,  4f72b1b40.jpg\n",
            "Processing image:  2501 ,  60bee807a.jpg\n",
            "Finished!\n",
            "Shape X-test:  (2537, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HNzk69iDTmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map5_per_image(label, predictions):\n",
        "    \"\"\"Computes the precision score of one image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    label : string\n",
        "            The true label of the image\n",
        "    predictions : list\n",
        "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"    \n",
        "    try:\n",
        "      return 1 / (predictions[:5].index(label) + 1)\n",
        "    except ValueError:\n",
        "      return 0.0\n",
        "\n",
        "def map5_per_set(labels, predictions):\n",
        "    \"\"\"Computes the average over multiple images.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    labels : list\n",
        "             A list of the true labels. (Only one true label per images allowed!)\n",
        "    predictions : list of list\n",
        "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"\n",
        "    return np.mean([map5_per_image(l, p) for l,p in zip(labels, predictions)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1RdJJQdkn0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "185ef1cf-2572-43d0-e8b9-9464c00589b0"
      },
      "source": [
        "gc.collect()\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weight.best.from_scratch.hdf5',\n",
        "                               verbose=1, save_best_only = True)\n",
        "model.fit(x_train_images, Y_train, epochs=20, batch_size=100, verbose=1,\n",
        "                   validation_data=(x_val_images, Y_val), callbacks=[checkpointer])\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 07:54:51.466195 139980295018368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20288 samples, validate on 2536 samples\n",
            "Epoch 1/20\n",
            "20288/20288 [==============================] - 17s 815us/step - loss: 6.2444 - acc: 0.3799 - val_loss: 5.9244 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 5.92436, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 2/20\n",
            "20288/20288 [==============================] - 9s 453us/step - loss: 5.7852 - acc: 0.3815 - val_loss: 5.8289 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00002: val_loss improved from 5.92436 to 5.82893, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 3/20\n",
            "20288/20288 [==============================] - 9s 456us/step - loss: 5.6727 - acc: 0.3815 - val_loss: 5.8362 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 5.82893\n",
            "Epoch 4/20\n",
            "20288/20288 [==============================] - 9s 448us/step - loss: 5.6334 - acc: 0.3815 - val_loss: 5.7664 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00004: val_loss improved from 5.82893 to 5.76639, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 5/20\n",
            "20288/20288 [==============================] - 9s 459us/step - loss: 5.5505 - acc: 0.3815 - val_loss: 5.7005 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00005: val_loss improved from 5.76639 to 5.70047, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 6/20\n",
            "20288/20288 [==============================] - 10s 472us/step - loss: 5.4712 - acc: 0.3815 - val_loss: 5.7181 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 5.70047\n",
            "Epoch 7/20\n",
            "20288/20288 [==============================] - 9s 464us/step - loss: 5.4104 - acc: 0.3815 - val_loss: 5.6742 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00007: val_loss improved from 5.70047 to 5.67419, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 8/20\n",
            "20288/20288 [==============================] - 9s 458us/step - loss: 5.3553 - acc: 0.3815 - val_loss: 5.6449 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00008: val_loss improved from 5.67419 to 5.64486, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 9/20\n",
            "20288/20288 [==============================] - 9s 461us/step - loss: 5.3061 - acc: 0.3815 - val_loss: 5.6461 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 5.64486\n",
            "Epoch 10/20\n",
            "20288/20288 [==============================] - 9s 453us/step - loss: 5.2653 - acc: 0.3815 - val_loss: 5.5921 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00010: val_loss improved from 5.64486 to 5.59209, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 11/20\n",
            "20288/20288 [==============================] - 9s 451us/step - loss: 5.2048 - acc: 0.3815 - val_loss: 5.5758 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00011: val_loss improved from 5.59209 to 5.57583, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 12/20\n",
            "20288/20288 [==============================] - 9s 459us/step - loss: 5.1562 - acc: 0.3815 - val_loss: 5.6185 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 5.57583\n",
            "Epoch 13/20\n",
            "20288/20288 [==============================] - 9s 453us/step - loss: 5.0983 - acc: 0.3815 - val_loss: 5.5892 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 5.57583\n",
            "Epoch 14/20\n",
            "20288/20288 [==============================] - 9s 457us/step - loss: 5.0479 - acc: 0.3815 - val_loss: 5.6475 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 5.57583\n",
            "Epoch 15/20\n",
            "20288/20288 [==============================] - 9s 462us/step - loss: 4.9975 - acc: 0.3815 - val_loss: 5.6088 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 5.57583\n",
            "Epoch 16/20\n",
            "20288/20288 [==============================] - 10s 469us/step - loss: 4.9427 - acc: 0.3815 - val_loss: 5.6147 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 5.57583\n",
            "Epoch 17/20\n",
            "20288/20288 [==============================] - 9s 451us/step - loss: 4.8957 - acc: 0.3815 - val_loss: 5.5830 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 5.57583\n",
            "Epoch 18/20\n",
            "20288/20288 [==============================] - 9s 461us/step - loss: 4.8555 - acc: 0.3815 - val_loss: 5.9071 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 5.57583\n",
            "Epoch 19/20\n",
            "20288/20288 [==============================] - 9s 467us/step - loss: 4.8004 - acc: 0.3815 - val_loss: 5.7303 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 5.57583\n",
            "Epoch 20/20\n",
            "20288/20288 [==============================] - 9s 463us/step - loss: 4.7637 - acc: 0.3815 - val_loss: 5.6548 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 5.57583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvw1d3YmeYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f8cb00c-6329-4f37-f50c-e20e79a180b6"
      },
      "source": [
        "model.load_weights('saved_models/weight.best.from_scratch.hdf5')\n",
        "pred = model.predict(x_test_images, verbose=1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2537/2537 [==============================] - 1s 302us/step\n",
            "(2537, 5005)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JuQhrdf9wa8",
        "colab_type": "text"
      },
      "source": [
        "## MAP@5 for Base CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c8c5d29b-dd0d-406f-ae00-1e07c9a6f5d5",
        "id": "_RTx0Sfs37Gk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions=[]\n",
        "for i, p in enumerate(pred):\n",
        "  predictions.append(le.inverse_transform(p.argsort()[-5:][::-1]).tolist())\n",
        "print('MAP@5 score for Base model = {}'.format(map5_per_set(X_test.Id, predictions )))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAP@5 score for Base model = 0.3834647221127316\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}