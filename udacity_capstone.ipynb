{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "udacity_capstone.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WtesfTyQBU3",
        "colab_type": "text"
      },
      "source": [
        "# Download the kaggle data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qGzsdQK16Z",
        "colab_type": "code",
        "outputId": "3662c668-d09e-483a-fa64-b119431929c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c humpback-whale-identification\n",
        "!rm -rf input\n",
        "!mkdir -p input\n",
        "!unzip -q train.zip -d input/train\n",
        "#!ls input/train\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpFPr0BgRgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f1664a5-6c56-4756-fdd3-3ebccd0eeee1"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mplimg\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF8I-wjLONtZ",
        "colab_type": "text"
      },
      "source": [
        "# Explore the training data.\n",
        "Let us explore the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6_zz3XOaSY",
        "colab_type": "code",
        "outputId": "8ae78143-f9f4-4dd9-d66f-727ab1416033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000e88ab.jpg</td>\n",
              "      <td>w_f48451c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0001f9222.jpg</td>\n",
              "      <td>w_c3d896a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00029d126.jpg</td>\n",
              "      <td>w_20df2c5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00050a15a.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0005c1ef8.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image         Id\n",
              "0  0000e88ab.jpg  w_f48451c\n",
              "1  0001f9222.jpg  w_c3d896a\n",
              "2  00029d126.jpg  w_20df2c5\n",
              "3  00050a15a.jpg  new_whale\n",
              "4  0005c1ef8.jpg  new_whale"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3bAW_bFTBax",
        "colab_type": "code",
        "outputId": "c08bc017-3c95-4bda-f29f-f6ee90a42af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Number of rows in train.csv', len(train_df))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in train.csv 25361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7vOENFsOhBP",
        "colab_type": "text"
      },
      "source": [
        "# Identify the data points\n",
        "\n",
        "## train.csv\n",
        "There are 25361 rows in train.csv.  Which corresponds to the image entries in train.zip\n",
        "We can see that the train.csv file has two data fields.  \n",
        "* Image : The whale image file name\n",
        "* Id is the whale Id.\n",
        "Each whale is assigned a unique Id.  The unidentified whale's are assigned an Id new_whale.  \n",
        "\n",
        "\n",
        "## train.zip\n",
        "There are 25361 image files in train.zip file.  It has been extracted to input/train folder.  The filename corresponds to the Image column in train.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJZxvxFdnAQ",
        "colab_type": "text"
      },
      "source": [
        "# Split the data into training, validation & test datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P63g4o2eCsV",
        "colab_type": "code",
        "outputId": "474cbe71-c024-4cee-90a0-b40e751cbd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "labels = train_df.Id\n",
        "# Encode labels to integers using sklearning.preprocessing.LabelEncoder\n",
        "# Convert the integer encoded array to category\n",
        "le = LabelEncoder()\n",
        "le.fit(labels)\n",
        "y_transform = np_utils.to_categorical(le.transform(labels), num_classes=len(le.classes_))\n",
        "\n",
        "X_train, X_tmp, Y_train, Y_tmp = train_test_split(train_df, y_transform, test_size=0.2, random_state=5)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test   = train_test_split(X_tmp, Y_tmp, test_size=0.5, random_state=5)\n",
        "\n",
        "print('Training, Validation & testing data size', len(X_train),len(X_val), len(X_test))\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training, Validation & testing data size 20288 2536 2537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bqz3rNkvKvf",
        "colab_type": "text"
      },
      "source": [
        "# Create a CNN to create a base line model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNl8gYrcbtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "94968f18-a9ce-4f8a-be64-6e6383b5c6b9"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 7, padding = 'same', activation = 'relu', \n",
        "          input_shape = (100, 100, 3))) #RGB image\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 7,  padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 7, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5005, activation='softmax'))\n",
        "\n",
        "print(model.output_shape)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 06:12:34.409164 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 06:12:34.429065 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 06:12:34.432000 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 06:12:34.451770 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0718 06:12:34.506905 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0718 06:12:34.519070 140297081849728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(None, 5005)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 16)      2368      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 33, 33, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 33, 33, 32)        25120     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        100416    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               32500     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5005)              2507505   \n",
            "=================================================================\n",
            "Total params: 2,667,909\n",
            "Trainable params: 2,667,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLevu9HUjD-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_images(data):\n",
        "    print(\"Preparing images\")\n",
        "    \n",
        "    images = np.zeros((len(data), 100, 100, 3))\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    for fig in data.Image:\n",
        "        #load images into images of size 100x100x3\n",
        "        img = image.load_img(\"input/train/\"+fig, target_size=(100, 100, 3))\n",
        "        x = image.img_to_array(img)\n",
        "        x = preprocess_input(x)\n",
        "        images[count] = x\n",
        "        if (count%500 == 0):\n",
        "            print(\"Processing image: \", count+1, \", \", fig)\n",
        "        count += 1\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    print(\"Finished!\")\n",
        "            \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bHgwkdQqMNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d10d3750-8148-44a6-ce8e-341143f41b5f"
      },
      "source": [
        "# model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 06:12:34.592480 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 06:12:34.624079 140297081849728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czcKfy5IjWqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddfcdab8-52a9-4b18-cd61-641019c3e7ce"
      },
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "x_train_images = prepare_images(X_train)\n",
        "x_train_images /= 255\n",
        "\n",
        "print(\"Shape X-train: \", x_train_images.shape)\n",
        "\n",
        "x_val_images = prepare_images(X_val)\n",
        "x_val_images /= 255\n",
        "\n",
        "print(\"Shape X-val: \", x_val_images.shape)\n",
        "\n",
        "x_test_images = prepare_images(X_test)\n",
        "x_test_images /= 255\n",
        "\n",
        "print(\"Shape X-test: \", x_test_images.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing images\n",
            "Processing image:  1 ,  5e2572252.jpg\n",
            "Processing image:  501 ,  b728ef1e9.jpg\n",
            "Processing image:  1001 ,  942ab5de3.jpg\n",
            "Processing image:  1501 ,  dd4cfa29f.jpg\n",
            "Processing image:  2001 ,  614f10ee7.jpg\n",
            "Processing image:  2501 ,  db9667359.jpg\n",
            "Processing image:  3001 ,  86c9aa515.jpg\n",
            "Processing image:  3501 ,  7f3aafbd2.jpg\n",
            "Processing image:  4001 ,  6f0c3deb4.jpg\n",
            "Processing image:  4501 ,  444b09aca.jpg\n",
            "Processing image:  5001 ,  f532c9318.jpg\n",
            "Processing image:  5501 ,  f2d3d0d0f.jpg\n",
            "Processing image:  6001 ,  6ca37fe7c.jpg\n",
            "Processing image:  6501 ,  3394e12db.jpg\n",
            "Processing image:  7001 ,  feddb3aa9.jpg\n",
            "Processing image:  7501 ,  3a8173905.jpg\n",
            "Processing image:  8001 ,  16ddf58df.jpg\n",
            "Processing image:  8501 ,  64b519010.jpg\n",
            "Processing image:  9001 ,  c2a02f80e.jpg\n",
            "Processing image:  9501 ,  770cb755e.jpg\n",
            "Processing image:  10001 ,  803515118.jpg\n",
            "Processing image:  10501 ,  5e8632b10.jpg\n",
            "Processing image:  11001 ,  5f37d323c.jpg\n",
            "Processing image:  11501 ,  204823b38.jpg\n",
            "Processing image:  12001 ,  27fdfe88c.jpg\n",
            "Processing image:  12501 ,  2272e1d48.jpg\n",
            "Processing image:  13001 ,  a7505ae38.jpg\n",
            "Processing image:  13501 ,  6faef4f7b.jpg\n",
            "Processing image:  14001 ,  788a2531c.jpg\n",
            "Processing image:  14501 ,  4e8713f2d.jpg\n",
            "Processing image:  15001 ,  a61a7cbf1.jpg\n",
            "Processing image:  15501 ,  f0109bc35.jpg\n",
            "Processing image:  16001 ,  f842d2d41.jpg\n",
            "Processing image:  16501 ,  1973d2873.jpg\n",
            "Processing image:  17001 ,  38b192e64.jpg\n",
            "Processing image:  17501 ,  b69a3106c.jpg\n",
            "Processing image:  18001 ,  898201c7f.jpg\n",
            "Processing image:  18501 ,  065fbc00f.jpg\n",
            "Processing image:  19001 ,  f5cfbf2df.jpg\n",
            "Processing image:  19501 ,  adaa80347.jpg\n",
            "Processing image:  20001 ,  a3785aebd.jpg\n",
            "Finished!\n",
            "Shape X-train:  (20288, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  f6992fe3c.jpg\n",
            "Processing image:  501 ,  3c9ccb9b5.jpg\n",
            "Processing image:  1001 ,  62a96dde1.jpg\n",
            "Processing image:  1501 ,  f7a34b30e.jpg\n",
            "Processing image:  2001 ,  03e3599f3.jpg\n",
            "Processing image:  2501 ,  b9c0dba6f.jpg\n",
            "Finished!\n",
            "Shape X-val:  (2536, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  448ae30f9.jpg\n",
            "Processing image:  501 ,  88766032d.jpg\n",
            "Processing image:  1001 ,  d5258d97c.jpg\n",
            "Processing image:  1501 ,  2e0f1128d.jpg\n",
            "Processing image:  2001 ,  4f72b1b40.jpg\n",
            "Processing image:  2501 ,  60bee807a.jpg\n",
            "Finished!\n",
            "Shape X-test:  (2537, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HNzk69iDTmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_per_image(label, predictions):\n",
        "    \"\"\"Computes the precision score of one image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    label : string\n",
        "            The true label of the image\n",
        "    predictions : list\n",
        "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"    \n",
        "    try:\n",
        "        return 1 / (predictions[:5].index(label) + 1)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def map_per_set(labels, predictions):\n",
        "    \"\"\"Computes the average over multiple images.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    labels : list\n",
        "             A list of the true labels. (Only one true label per images allowed!)\n",
        "    predictions : list of list\n",
        "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "    \"\"\"\n",
        "    return np.mean([map_per_image(l, p) for l,p in zip(labels, predictions)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1RdJJQdkn0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07b05e76-9416-4016-cc60-37bb1e8b5822"
      },
      "source": [
        "gc.collect()\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weight.best.from_scratch.hdf5',\n",
        "                               verbose=1, save_best_only = True)\n",
        "model.fit(x_train_images, Y_train, epochs=25, batch_size=100, verbose=1,\n",
        "                   validation_data=(x_val_images, Y_val), callbacks=[checkpointer])\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 06:17:11.679155 140297081849728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20288 samples, validate on 2536 samples\n",
            "Epoch 1/25\n",
            "20288/20288 [==============================] - 21s 1ms/step - loss: 6.2843 - acc: 0.3799 - val_loss: 5.9196 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 5.91957, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 2/25\n",
            "20288/20288 [==============================] - 14s 703us/step - loss: 5.7776 - acc: 0.3815 - val_loss: 5.8347 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00002: val_loss improved from 5.91957 to 5.83468, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 3/25\n",
            "20288/20288 [==============================] - 14s 702us/step - loss: 5.6728 - acc: 0.3815 - val_loss: 5.7923 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00003: val_loss improved from 5.83468 to 5.79233, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 4/25\n",
            "20288/20288 [==============================] - 14s 699us/step - loss: 5.6209 - acc: 0.3815 - val_loss: 5.7880 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00004: val_loss improved from 5.79233 to 5.78796, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 5/25\n",
            "20288/20288 [==============================] - 14s 699us/step - loss: 5.5498 - acc: 0.3815 - val_loss: 5.7039 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00005: val_loss improved from 5.78796 to 5.70395, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 6/25\n",
            "20288/20288 [==============================] - 14s 701us/step - loss: 5.4750 - acc: 0.3815 - val_loss: 5.6509 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00006: val_loss improved from 5.70395 to 5.65088, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 7/25\n",
            "20288/20288 [==============================] - 14s 700us/step - loss: 5.4089 - acc: 0.3815 - val_loss: 5.6954 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 5.65088\n",
            "Epoch 8/25\n",
            "20288/20288 [==============================] - 14s 701us/step - loss: 5.3566 - acc: 0.3815 - val_loss: 5.6062 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00008: val_loss improved from 5.65088 to 5.60623, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 9/25\n",
            "20288/20288 [==============================] - 14s 705us/step - loss: 5.3032 - acc: 0.3815 - val_loss: 5.6413 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 5.60623\n",
            "Epoch 10/25\n",
            "20288/20288 [==============================] - 14s 705us/step - loss: 5.2561 - acc: 0.3815 - val_loss: 5.5977 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00010: val_loss improved from 5.60623 to 5.59775, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 11/25\n",
            "20288/20288 [==============================] - 14s 703us/step - loss: 5.2028 - acc: 0.3815 - val_loss: 5.5610 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00011: val_loss improved from 5.59775 to 5.56098, saving model to saved_models/weight.best.from_scratch.hdf5\n",
            "Epoch 12/25\n",
            "20288/20288 [==============================] - 14s 697us/step - loss: 5.1508 - acc: 0.3815 - val_loss: 5.5750 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 5.56098\n",
            "Epoch 13/25\n",
            "20288/20288 [==============================] - 14s 703us/step - loss: 5.0947 - acc: 0.3815 - val_loss: 5.6447 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 5.56098\n",
            "Epoch 14/25\n",
            "20288/20288 [==============================] - 14s 697us/step - loss: 5.0303 - acc: 0.3815 - val_loss: 5.5925 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 5.56098\n",
            "Epoch 15/25\n",
            "20288/20288 [==============================] - 14s 710us/step - loss: 4.9812 - acc: 0.3815 - val_loss: 5.6228 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 5.56098\n",
            "Epoch 16/25\n",
            "20288/20288 [==============================] - 14s 702us/step - loss: 4.9279 - acc: 0.3815 - val_loss: 5.5842 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 5.56098\n",
            "Epoch 17/25\n",
            "20288/20288 [==============================] - 14s 699us/step - loss: 4.8731 - acc: 0.3815 - val_loss: 5.6625 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 5.56098\n",
            "Epoch 18/25\n",
            "20288/20288 [==============================] - 14s 702us/step - loss: 4.8111 - acc: 0.3815 - val_loss: 5.6822 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 5.56098\n",
            "Epoch 19/25\n",
            "20288/20288 [==============================] - 14s 705us/step - loss: 4.7666 - acc: 0.3815 - val_loss: 5.6455 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 5.56098\n",
            "Epoch 20/25\n",
            "20288/20288 [==============================] - 14s 700us/step - loss: 4.7174 - acc: 0.3815 - val_loss: 5.6281 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 5.56098\n",
            "Epoch 21/25\n",
            "20288/20288 [==============================] - 14s 698us/step - loss: 4.6787 - acc: 0.3815 - val_loss: 5.7247 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 5.56098\n",
            "Epoch 22/25\n",
            "20288/20288 [==============================] - 14s 698us/step - loss: 4.6325 - acc: 0.3815 - val_loss: 5.8377 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 5.56098\n",
            "Epoch 23/25\n",
            "20288/20288 [==============================] - 14s 696us/step - loss: 4.6036 - acc: 0.3816 - val_loss: 5.6581 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 5.56098\n",
            "Epoch 24/25\n",
            "20288/20288 [==============================] - 14s 698us/step - loss: 4.5531 - acc: 0.3818 - val_loss: 5.7900 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 5.56098\n",
            "Epoch 25/25\n",
            "20288/20288 [==============================] - 14s 701us/step - loss: 4.5260 - acc: 0.3818 - val_loss: 5.8182 - val_acc: 0.3825\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 5.56098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvw1d3YmeYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6797b179-63dd-4652-f621-1ec3dc346553"
      },
      "source": [
        "model.load_weights('saved_models/weight.best.from_scratch.hdf5')\n",
        "pred = model.predict(x_test_images, verbose=1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2537/2537 [==============================] - 1s 382us/step\n",
            "(2537, 5005)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f2cc4204-5352-447c-cd3f-b6ca3ff6ef44",
        "id": "_RTx0Sfs37Gk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions=[]\n",
        "for i, p in enumerate(pred):\n",
        "  predictions.append(le.inverse_transform(p.argsort()[-5:][::-1]).tolist())\n",
        "print(map_per_set(X_test.Id, predictions ))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38368808303770857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}