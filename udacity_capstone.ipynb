{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "udacity_capstone.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WtesfTyQBU3",
        "colab_type": "text"
      },
      "source": [
        "# Download the kaggle data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpFPr0BgRgi",
        "colab_type": "code",
        "outputId": "5bcf3bcd-9b91-45ce-d660-86e864aaffe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mplimg\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpwABk-4COFN",
        "colab_type": "code",
        "outputId": "4f9262ab-242d-4f89-a1c2-185012f99d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.7.1\r\n",
            "appnope==0.1.0\r\n",
            "astor==0.8.0\r\n",
            "attrs==19.1.0\r\n",
            "backcall==0.1.0\r\n",
            "bleach==3.1.0\r\n",
            "Bottleneck==1.2.1\r\n",
            "certifi==2018.8.24\r\n",
            "cffi==1.12.3\r\n",
            "Click==7.0\r\n",
            "colorama==0.4.1\r\n",
            "cycler==0.10.0\r\n",
            "decorator==4.4.0\r\n",
            "defusedxml==0.6.0\r\n",
            "Django==2.2.3\r\n",
            "entrypoints==0.3\r\n",
            "enum34==1.1.6\r\n",
            "gast==0.2.2\r\n",
            "glob2==0.7\r\n",
            "google-pasta==0.1.7\r\n",
            "grpcio==1.22.0\r\n",
            "h5py==2.8.0\r\n",
            "image==1.5.27\r\n",
            "imageio==2.5.0\r\n",
            "ipykernel==4.6.1\r\n",
            "ipython==7.6.1\r\n",
            "ipython-genutils==0.2.0\r\n",
            "ipywidgets==7.5.0\r\n",
            "jedi==0.14.1\r\n",
            "Jinja2==2.10.1\r\n",
            "joblib==0.13.2\r\n",
            "jsonschema==3.0.1\r\n",
            "jupyter==1.0.0\r\n",
            "jupyter-client==5.3.1\r\n",
            "jupyter-console==6.0.0\r\n",
            "jupyter-core==4.5.0\r\n",
            "jupyter-http-over-ws==0.0.6\r\n",
            "Keras==2.2.4\r\n",
            "Keras-Applications==1.0.8\r\n",
            "Keras-Preprocessing==1.1.0\r\n",
            "kiwisolver==1.1.0\r\n",
            "Markdown==3.1.1\r\n",
            "MarkupSafe==1.1.1\r\n",
            "matplotlib==3.0.3\r\n",
            "mistune==0.8.4\r\n",
            "mkl-fft==1.0.6\r\n",
            "mkl-random==1.0.1\r\n",
            "nbconvert==5.5.0\r\n",
            "nbformat==4.4.0\r\n",
            "networkx==2.3\r\n",
            "notebook==5.2.2\r\n",
            "numpy==1.16.4\r\n",
            "olefile==0.46\r\n",
            "opencv-python==3.4.5.20\r\n",
            "pandas==0.24.2\r\n",
            "pandocfilters==1.4.2\r\n",
            "parso==0.5.1\r\n",
            "pexpect==4.7.0\r\n",
            "pickleshare==0.7.5\r\n",
            "Pillow==4.3.0\r\n",
            "plaidbench==0.6.3\r\n",
            "plaidml==0.6.3\r\n",
            "plaidml-keras==0.6.3\r\n",
            "prompt-toolkit==2.0.9\r\n",
            "protobuf==3.9.0\r\n",
            "ptyprocess==0.6.0\r\n",
            "pycparser==2.19\r\n",
            "Pygments==2.4.2\r\n",
            "pyparsing==2.4.0\r\n",
            "pyrsistent==0.15.3\r\n",
            "python-dateutil==2.8.0\r\n",
            "pytz==2019.1\r\n",
            "PyWavelets==1.0.3\r\n",
            "PyYAML==5.1.1\r\n",
            "pyzmq==17.0.0\r\n",
            "qtconsole==4.5.1\r\n",
            "scikit-image==0.15.0\r\n",
            "scikit-learn==0.21.2\r\n",
            "scipy==1.3.0\r\n",
            "six==1.12.0\r\n",
            "sklearn==0.0\r\n",
            "sklearn-pandas==1.8.0\r\n",
            "sqlparse==0.3.0\r\n",
            "tensorboard==1.14.0\r\n",
            "tensorflow==1.14.0\r\n",
            "tensorflow-estimator==1.14.0\r\n",
            "termcolor==1.1.0\r\n",
            "terminado==0.8.2\r\n",
            "testpath==0.4.2\r\n",
            "Theano==1.0.4\r\n",
            "tornado==4.5.3\r\n",
            "tqdm==4.28.1\r\n",
            "traitlets==4.3.2\r\n",
            "wcwidth==0.1.7\r\n",
            "webencodings==0.5.1\r\n",
            "Werkzeug==0.15.5\r\n",
            "widgetsnbextension==3.5.0\r\n",
            "wrapt==1.11.2\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF8I-wjLONtZ",
        "colab_type": "text"
      },
      "source": [
        "# Explore the training data.\n",
        "Let us explore the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6_zz3XOaSY",
        "colab_type": "code",
        "outputId": "8205e0c3-300a-4c48-c5ce-5a82cdc98e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Image         Id\n",
              "0  0000e88ab.jpg  w_f48451c\n",
              "1  0001f9222.jpg  w_c3d896a\n",
              "2  00029d126.jpg  w_20df2c5\n",
              "3  00050a15a.jpg  new_whale\n",
              "4  0005c1ef8.jpg  new_whale"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000e88ab.jpg</td>\n",
              "      <td>w_f48451c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0001f9222.jpg</td>\n",
              "      <td>w_c3d896a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00029d126.jpg</td>\n",
              "      <td>w_20df2c5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00050a15a.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0005c1ef8.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3bAW_bFTBax",
        "colab_type": "code",
        "outputId": "deef5beb-f7a3-4347-e394-bc10be9053bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Number of rows in train.csv', len(train_df))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in train.csv 25361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7vOENFsOhBP",
        "colab_type": "text"
      },
      "source": [
        "# Identify the data points\n",
        "\n",
        "## train.csv\n",
        "There are 25361 rows in train.csv.  Which corresponds to the image entries in train.zip\n",
        "We can see that the train.csv file has two data fields.  \n",
        "* Image : The whale image file name\n",
        "* Id is the whale Id.\n",
        "Each whale is assigned a unique Id.  The unidentified whale's are assigned an Id new_whale.  \n",
        "\n",
        "\n",
        "## train.zip\n",
        "There are 25361 image files in train.zip file.  It has been extracted to input/train folder.  The filename corresponds to the Image column in train.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJZxvxFdnAQ",
        "colab_type": "text"
      },
      "source": [
        "# Split the data into training, validation & test datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P63g4o2eCsV",
        "colab_type": "code",
        "outputId": "9275c6c1-d5a8-4531-976d-41d1d4a5a908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "labels = train_df.Id\n",
        "# Encode labels to integers using sklearning.preprocessing.LabelEncoder\n",
        "# Convert the integer encoded array to category\n",
        "le = LabelEncoder()\n",
        "le.fit(labels)\n",
        "y_transform = np_utils.to_categorical(le.transform(labels), num_classes=len(le.classes_))\n",
        "\n",
        "X_train, X_tmp, Y_train, Y_tmp = train_test_split(train_df, y_transform, test_size=0.2, random_state=5)\n",
        "\n",
        "X_val, X_test, Y_val, Y_test   = train_test_split(X_tmp, Y_tmp, test_size=0.5, random_state=5)\n",
        "\n",
        "print('Training, Validation & testing data size', len(X_train),len(X_val), len(X_test))\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training, Validation & testing data size 20288 2536 2537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra5YW9NSxmyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_images(data):\n",
        "    print(\"Preparing images\")\n",
        "    images = np.zeros((len(data), 100, 100, 3))\n",
        "    count = 0\n",
        "    \n",
        "    for fig in data.Image:\n",
        "        #load images into images of size 100x100x3\n",
        "        img = image.load_img(\"input/train/\"+fig, target_size=(100, 100, 3))\n",
        "        x = image.img_to_array(img)\n",
        "        x = preprocess_input(x)\n",
        "        images[count] = x\n",
        "        if (count%500 == 0):\n",
        "            print(\"Processing image: \", count+1, \", \", fig)\n",
        "        count += 1\n",
        "    count = 0\n",
        "    print(\"Finished!\")      \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bqz3rNkvKvf",
        "colab_type": "text"
      },
      "source": [
        "# Create a CNN to create a base line model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNl8gYrcbtY",
        "colab_type": "code",
        "outputId": "c8cc31aa-8ec2-4c22-cc5e-5f0da194a0b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 7, padding = 'same', activation = 'relu', \n",
        "          input_shape = (100, 100, 3))) #RGB image\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 7,  padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 7, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5005, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 16)      2368      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 33, 33, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 33, 33, 32)        25120     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        100416    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               32500     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5005)              2507505   \n",
            "=================================================================\n",
            "Total params: 2,667,909\n",
            "Trainable params: 2,667,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bHgwkdQqMNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czcKfy5IjWqS",
        "colab_type": "code",
        "outputId": "6a200e3a-eae7-4ea9-ef78-564d740c84b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "x_train_images = prepare_images(X_train)\n",
        "x_train_images /= 255\n",
        "\n",
        "print(\"Shape X-train: \", x_train_images.shape)\n",
        "\n",
        "x_val_images = prepare_images(X_val)\n",
        "x_val_images /= 255\n",
        "\n",
        "print(\"Shape X-val: \", x_val_images.shape)\n",
        "\n",
        "x_test_images = prepare_images(X_test)\n",
        "x_test_images /= 255\n",
        "\n",
        "print(\"Shape X-test: \", x_test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing images\n",
            "Processing image:  1 ,  5e2572252.jpg\n",
            "Processing image:  501 ,  b728ef1e9.jpg\n",
            "Processing image:  1001 ,  942ab5de3.jpg\n",
            "Processing image:  1501 ,  dd4cfa29f.jpg\n",
            "Processing image:  2001 ,  614f10ee7.jpg\n",
            "Processing image:  2501 ,  db9667359.jpg\n",
            "Processing image:  3001 ,  86c9aa515.jpg\n",
            "Processing image:  3501 ,  7f3aafbd2.jpg\n",
            "Processing image:  4001 ,  6f0c3deb4.jpg\n",
            "Processing image:  4501 ,  444b09aca.jpg\n",
            "Processing image:  5001 ,  f532c9318.jpg\n",
            "Processing image:  5501 ,  f2d3d0d0f.jpg\n",
            "Processing image:  6001 ,  6ca37fe7c.jpg\n",
            "Processing image:  6501 ,  3394e12db.jpg\n",
            "Processing image:  7001 ,  feddb3aa9.jpg\n",
            "Processing image:  7501 ,  3a8173905.jpg\n",
            "Processing image:  8001 ,  16ddf58df.jpg\n",
            "Processing image:  8501 ,  64b519010.jpg\n",
            "Processing image:  9001 ,  c2a02f80e.jpg\n",
            "Processing image:  9501 ,  770cb755e.jpg\n",
            "Processing image:  10001 ,  803515118.jpg\n",
            "Processing image:  10501 ,  5e8632b10.jpg\n",
            "Processing image:  11001 ,  5f37d323c.jpg\n",
            "Processing image:  11501 ,  204823b38.jpg\n",
            "Processing image:  12001 ,  27fdfe88c.jpg\n",
            "Processing image:  12501 ,  2272e1d48.jpg\n",
            "Processing image:  13001 ,  a7505ae38.jpg\n",
            "Processing image:  13501 ,  6faef4f7b.jpg\n",
            "Processing image:  14001 ,  788a2531c.jpg\n",
            "Processing image:  14501 ,  4e8713f2d.jpg\n",
            "Processing image:  15001 ,  a61a7cbf1.jpg\n",
            "Processing image:  15501 ,  f0109bc35.jpg\n",
            "Processing image:  16001 ,  f842d2d41.jpg\n",
            "Processing image:  16501 ,  1973d2873.jpg\n",
            "Processing image:  17001 ,  38b192e64.jpg\n",
            "Processing image:  17501 ,  b69a3106c.jpg\n",
            "Processing image:  18001 ,  898201c7f.jpg\n",
            "Processing image:  18501 ,  065fbc00f.jpg\n",
            "Processing image:  19001 ,  f5cfbf2df.jpg\n",
            "Processing image:  19501 ,  adaa80347.jpg\n",
            "Processing image:  20001 ,  a3785aebd.jpg\n",
            "Finished!\n",
            "Shape X-train:  (20288, 100, 100, 3)\n",
            "Preparing images\n",
            "Processing image:  1 ,  f6992fe3c.jpg\n",
            "Processing image:  501 ,  3c9ccb9b5.jpg\n",
            "Processing image:  1001 ,  62a96dde1.jpg\n",
            "Processing image:  1501 ,  f7a34b30e.jpg\n",
            "Processing image:  2001 ,  03e3599f3.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1RdJJQdkn0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weight.best.from_scratch.hdf5',\n",
        "                               verbose=1, save_best_only = True)\n",
        "model.fit(x_train_images, Y_train, epochs=20, batch_size=100, verbose=1,\n",
        "                   validation_data=(x_val_images, Y_val), callbacks=[checkpointer])\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvw1d3YmeYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('saved_models/weight.best.from_scratch.hdf5')\n",
        "pred = model.predict(x_test_images, verbose=1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JuQhrdf9wa8",
        "colab_type": "text"
      },
      "source": [
        "## MAP@5 for Base CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_RTx0Sfs37Gk",
        "colab": {}
      },
      "source": [
        "import map5_method as map5\n",
        "predictions=[]\n",
        "for i, p in enumerate(pred):\n",
        "  predictions.append(le.inverse_transform(p.argsort()[-5:][::-1]).tolist())\n",
        "print('MAP@5 score for Base model = {}'.format(map5_per_set(X_test.Id, predictions )))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYw1BWYVJiZi",
        "colab_type": "text"
      },
      "source": [
        "# Using VGG16 and Transfer learning\n",
        "\n",
        "To reduce training time without sacrificing accuracy, lets train a CNN using transfer learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wulZQnv2KHfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}